{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1ea7abad-bed7-4c3a-bf0e-7299602cad21",
   "metadata": {},
   "source": [
    "QUES NO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070df11-2d38-4683-b181-e868deab21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERFITTING \n",
    "overfitting is a condition in which during the training the data is performed with good  accuracy but when \n",
    "it comes for the tested then its accuracy is decrease \n",
    "in another word we can say that model making is coorect but it done the wrong pridiction\n",
    "UNDERFITTING\n",
    "underfitting is a condition in which the data is performed not very well during the training but it perform \n",
    "very well during the testing\n",
    "in another word we can define as the data model is unable to capture the relationship b/w  input and output\n",
    "variable and create the large error b/t the training dataset and unseen data\n",
    "\n",
    "#we can deal with the underfitting training data.\n",
    "increase model complexity.\n",
    "Increase the number of features, performing feature engineering.\n",
    "Remove noise from the data.\n",
    "Increase the number of epochs or increase the duration of training to get better results.\n",
    "# we  can deal with the overfitting by these ways\n",
    "increase training data.\n",
    "Reduce model complexity.\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as \n",
    "soon as loss begins to increase stop training).\n",
    "Ridge Regularization and Lasso Regularization.\n",
    "Use dropout for neural networks to tackle overfitting.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cb048f1-951c-4c45-b857-3f88c6710616",
   "metadata": {},
   "source": [
    "QUES NO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e60b3-c26c-41f0-ba08-819bab02575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1 : Early stopping\n",
    "\n",
    "Early stopping pauses the training phase before the machine learning model learns the noise in the data\n",
    "However getting the timing right is important else the model will still not give accurate results.\n",
    "2 : Pruning \n",
    "\n",
    "it help us to identify the most important feature in the training set and eliminating the irrelivent ones \n",
    "as it help in the prediction accurate final outcome from model\n",
    "3 : Regularisation \n",
    "\n",
    "there are number of the training of dataset are occoured to reduce overfitting that means that it try to\n",
    "remove to those factor which does not impact the prediction outcome by grading the by grading\n",
    "features based on importance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528f673-65e7-4cb4-9a03-6720190b1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES NO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba6c1b-74f9-4ba1-9c36-1466f31a72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1\n",
    "High bias and low variance.\n",
    "2\n",
    "The size of the training dataset used is not enough.\n",
    "3\n",
    "The model is too simple.\n",
    "4\n",
    "Training data is not cleaned and also contains noise in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fb84d-3780-494b-9444-6f5d777e14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES NO 4\n",
    "TRADEOFF IN MACHINE LEARNING\n",
    "\n",
    "tradeoff between a model’s ability to minimize bias and variance which is referred to as the best \n",
    "solution for selecting a value of Regularization constant\n",
    "\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are\n",
    "trying to predict WHERAS The variability of model prediction for a given data point which tells us the \n",
    "spread of our data is called the variance of the model\n",
    "\n",
    "Being high in biasing gives a large error in training as well as testing data. \n",
    "It recommended that an algorithm should always be low-biased to avoid the problem of underfitting\n",
    "The model with high variance has a very complex fit to the training data and thus is not able to fit \n",
    "accurately on the data which it hasn’t seen before\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22798ba4-412b-4488-901f-819819557bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES NO 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d796afc-4ee6-42e8-9f8a-883e17dd2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "common methods for detecting overfitting and underfitting in machine learning models\n",
    "\n",
    "A statistical model or a machine learning algorithm is said to have underfitting when it cannot \n",
    "capture the underlying trend of the data, EX, it only performs well on training data but performs\n",
    "poorly on testing data\n",
    "A statistical model is said to be overfitted when the model does not make accurate predictions on \n",
    "testing data. When a model gets trained with so much data, it starts learning from the noise and \n",
    "inaccurate data entries in our data set\n",
    "\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking\n",
    "at the prediction error on the training data and the evaluation data.\n",
    " the difference between an underfitting and overfitting experimentally by comparing fitted\n",
    "models to training-data and test-data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8021d-ddb5-4064-8171-2014611dc42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES NO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d04b0c-4ce5-4d15-acb2-4f280d9fb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A high bias model has the following characteristics\n",
    "\n",
    "Failure to gather proper data trends.\n",
    "Possibility of having an improper fit.\n",
    "More generic and simplistic in an excessive degree.\n",
    "A high frequency of errors\n",
    "\n",
    "A high variance model has the following characteristics \n",
    "The presence of noise in the data set\n",
    "There is a possibility of overfitting.\n",
    "Complex models.\n",
    "Making an effort to bring all of the data points as close together as possible\n",
    "\n",
    "EXAMPLE OF HIGH BIASED MODEL\n",
    "high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis\n",
    "and Logistic Regression\n",
    "\n",
    "EXAMPLE OF HIGH BIASED MODEL\n",
    "Those with high variance include decision trees, support vector machines and k-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399151a-dfd0-47e4-88f1-07013bb9f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES NO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea182f8-0ad4-4a27-a422-2af14ee65e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization is a technique used to reduce errors by fitting the function appropriately on the\n",
    "given training set and avoiding overfitting. The commonly used regularization techniques are : \n",
    "\n",
    "Lasso Regularization – L1 Regularization\n",
    "Ridge Regularization – L2 Regularization\n",
    "\n",
    "Regularization removes extra weights from the selected features and redistributes the weights evenly.\n",
    "This means that regularization discourages the learning of a model of both high complexity and \n",
    "flexibility. A highly flexible model is one that possesses the freedom to fit as many data points as\n",
    "possible.\n",
    "\n",
    "#some common regularization techniques \n",
    "\n",
    "1 : Ridge Regression (L2 Regularization)\n",
    "Ridge regression is also called L2 norm or regularization.\n",
    "\n",
    "When using this technique, we add the sum of weight’s square to a loss function and thus create a\n",
    "new loss function\n",
    "\n",
    "2 : Lasso Regression (L1 Regularization)\n",
    "\n",
    "\n",
    "\n",
    "This technique is different from ridge regression as it uses absolute weight values for normalization. \n",
    "λ is again a tuning parameter and behaves in the same as it does when using ridge regression.\n",
    "\n",
    "As loss function only considers absolute weights, optimization algorithms penalize higher weight values.\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb9f5b-3d4c-48b0-a583-fc481491d930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
